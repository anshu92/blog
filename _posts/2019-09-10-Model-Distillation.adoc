= Model Distillation
:hp-image: https://github.com/anshu92/blog/raw/gh-pages/images/carolien-van-oijen-GRlRHqEqZTc-unsplash.jpg
:published_at: 2019-09-10
:hp-tags: distillation, machine learning

[.lead]
*How most of the information in large models can be transferred to a small model using soft targets, and what that says about the relationship of information to the dynamics of learning.*

image::https://github.com/anshu92/blog/raw/gh-pages/images/carolien-van-oijen-GRlRHqEqZTc-unsplash.jpg[Bee]

'''
.Recent NLP language models
[width="50%",cols="<,<",frame="all",grid="all"]
|===
|*model*
|*parameters*

|BERT-base
|110 million

|BERT-large
|340 million

|Facebook XLM
|665 million

|OpenAI GPT-2
|774 million
|===
'''

The upward trend of model sizes raises hurdles for the application of these models in the shape of computation and scalability, and requires decisions on the trade-off between accuracy, potency and deployability. Following reading http://www.nlp.town/blog/distilling-bert/[this blog post], I decided to try to summarize (distill) the concept of model distillation, and talk about why this struck me as such an interesting idea.

.Model Distillation. graphic by Anshuman Sahoo
image::https://github.com/anshu92/blog/raw/gh-pages/images/distill.png[Model Distillation]

'''

As shown above, the method of distillation relies on the idea of *_soft targets_* and *_softmax temperature_*.

'''

.Softmax Function with Temperature
image::https://github.com/anshu92/blog/raw/gh-pages/images/tempsoftmax.png[Model Distillation,align="center"]

'''

https://arxiv.org/pdf/1503.02531.pdf[Hinton et al., 2015] introduced the concept of "softmax temperature". The probability p~i~ of class i is calculated from the logits z. T is the temperature parameter - as you can see, setting T = 1 gives us the standard softmax function. In the paper, they also found that if the ground truth labels are available, it improves the model if the loss to optimize includes training on ground truth labels in addition to the soft target outputs of the teacher model(as shown in the figure, student loss is added to distillation loss).

On a philosophical line of thought, the paper presents an analogy of some insects in nature that optimize based on their stage-of-life requirement - larval forms to extract nutrition from environment and an adult form for travellig and reproduction; whereas cumbersome, large and often ensemble models remain the same during training and deployment. A conceptual block that may explain our hesitation of modifying trained models is our assumption that changing learned parameters may lead to loss of knowledge. Another assumption made is that the optimizing an objective function for the training set is close to optimizing the user's true objective - generalizing well to unseen data. However, ideal generalization to the user objective requires knowledge that might not be available in the training data.



