// = 
// See https://hubpress.gitbooks.io/hubpress-knowledgebase/content/ for information about the parameters.
// :hp-image: /covers/cover.png
// :published_at: 2019-01-31
// :hp-tags: HubPress, Blog, Open_Source,
// :hp-alt-title: My English Title

= 4: Variable Elimination Algorithm in Probabilistic Graph Inference
:hp-tags: probabilistic graphical models, pgm, inference

*_helpful links:_*

- http://spark-university.s3.amazonaws.com/stanford-pgm/slides/3.2.1-Inf-VE-Alg.pdf[summary of a section of course taught by Daphne Kohler, Stanford]
- <https://ermongroup.github.io/cs228-notes/inference/ve/>
- http://pgmlearning.herokuapp.com/vElimApp[Cool simulation of variable elimination]

Probabilistic graphical models represent rich representational structure to model processes. Inference then, is the process of getting insights from the structure in response to queries, and in the presence of certain evidence or observations.

Among these set of models, from Bayesian to Markov models where we have a set of observations say 'e' about some variable 'E', we have two kinds of queries  that are of interest - 

1. *Conditional probability query* - we are looking for a subset of all graph variables Y, i.e., we are trying to compute P(Y | E=e)

2. *Maximum a posteriori (MAP) query* - we are looking for all values of Y, where Y is all variables except the evidence E that maximizes P(Y | E=e) (argmax_y p(y=y | E=e)

Both these problems are theoretically NP-hard but that is the worst case situation. In general there are many strategies that make inference on PGMs tractable. There are many inference algorithms like Variable elimination, Message passing over a graph, belief propogation, variational approximation, Random sampling instantiations (Markov chain Monte Carlo, importance sampling).

Variable Elimination is a form of *memoization/dynamic programming algorithm*, where we compute factors as we try to eliminate variables along a graph. 

In it's simplest form, we can illustrate its working on a chain of variables (refer to slides provided in the link above). By marginalizing over a series of factors determined by order, which determines the run time of the algorithm, we can progressively eliminate 'local' variables from a factor. Finding the right order of variables is an NP-hard problem. 

image::https://image.slidesharecdn.com/lecture11xing-150527174444-lva1-app6892/95/lecture11-xing-17-638.jpg?cb=1432748719[Example]


Some useful strategies for determining the order of variables to eliminate include min-neighbors (Choose a variable with the fewest dependent variables), min-weight (Choose variables to minimize the product of the cardinalities of its dependent variables), min-fill (Choose vertices to minimize the size of the factor that will be added to the graph)




