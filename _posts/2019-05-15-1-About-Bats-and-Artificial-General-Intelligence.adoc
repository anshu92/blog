# 1: About Bats and Artificial General Intelligence

In many works of fiction where an AI agent comes to life, often the first interaction is an emotional one. Vengeance, lust, fear or joy are tools used to convince us that the agent is human-like intelligent in its motives and actions. And our perceptions of what AGI should look like are polluted by the specificity of our perceptions regarding intelligent agents. A recent paper I read by Thomas Nagel titled _What is it like to be a bat?_ ( <https://en.wikipedia.org/wiki/What_Is_it_Like_to_Be_a_Bat%3F> ) brought to the fore some points about such reductionist viewpoints that I felt were important.

#### Rallying against reductionism
Nagel argues that depicting consciousness in terms of material explainations such as neurological signals leaves out important subjective elements. Like flavors of ice cream, there is something in the sense of being a particular organism - a subjective character of experience that cannot be ignored. Reductionist explanations are compatible with the absence of such subjectivity and hence lack something

#### Subjectivity vs Objectivity
BATS! Nagel chose bats for this analogy because they are close enough to us in the phylogenetic tree to be relevant but present a range of activity and sensory apparatus that are very different from us. Bats use sonar/echo location as their primary sensory system. Now we objectively can understand how they send clicks out and their brains correlate the expected return signals to volume, depth and distance. But subjectively, their experience is definitely unlike anything we can imagine. So can any method allow us to extrapolate the inner life of a bat? Our imagination is limited by our experience since it is our perception of reality that provides the basic material to it. I can imagine webbed arms, poor vision and hanging upside down from the ceiling. That _might_ be good enough to tell me how a bat behaves but not what it is like to be a bat. In a similar way, although a Martian might be able to objectively understand the concept of lighting - upon examining our neurons, would they be able to understand the _subjectively_ different function lightning/electricity plays in our brains? All this is to highlight the upper limits of perceptual abilities and the fact that ignoring this is doing a disservice to ever creating any form of 'AI' or even understanding what manufactured intelligence might look like beyond those crafted to appease our narrow imaginative limits. It is a crude form of cognitive dissonance that we are foolng ourselves into.

#### Facts vs conceptual schemes
Another area of caution is to accept that there are humanly inaccesible facts, and in our inability to know what we don't know, we create conceptual schemes that 'fit'. Objectivity is simply reducing our dependence on species/situation specific points towards the object of investigation. However, greater objectivity takes us farther from the real nature of the phenomena.



